---
title: (DynamoDBで)苦しかったときの話をしようか
tags:
  - AWS
  - DynamoDB
private: false
updated_at: '2020-10-06T18:13:08+09:00'
id: c4713bee2170f0838cbb
organization_url_name: null
slide: true
ignorePublish: false
---
# はじめに

本記事は**AWS**の**DynamoDB**を使った開発で**苦しんだ**経験をまとめたものです。ちなみにタイトルの元ネタは[これ](https://www.amazon.co.jp/%E8%8B%A6%E3%81%97%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AE%E8%A9%B1%E3%82%92%E3%81%97%E3%82%88%E3%81%86%E3%81%8B-%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E3%83%9E%E3%83%B3%E3%81%AE%E7%88%B6%E3%81%8C%E6%88%91%E3%81%8C%E5%AD%90%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AB%E6%9B%B8%E3%81%8D%E3%81%9F%E3%82%81%E3%81%9F%E3%80%8C%E5%83%8D%E3%81%8F%E3%81%93%E3%81%A8%E3%81%AE%E6%9C%AC%E8%B3%AA%E3%80%8D-%E6%A3%AE%E5%B2%A1-%E6%AF%85/dp/4478107823/ref=sr_1_1?adgrpid=71273059631&dchild=1&gclid=EAIaIQobChMI0d-z1s2f7AIVGFVgCh1_VAmoEAAYASAAEgKoIPD_BwE&hvadid=341042880623&hvdev=c&hvlocphy=1009314&hvnetw=g&hvqmt=e&hvrand=2727989169983540152&hvtargid=kwd-691599437442&hydadcr=3636_11125055&jp-ad-ap=0&keywords=%E8%8B%A6%E3%81%97%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AE%E8%A9%B1%E3%82%92%E3%81%97%E3%82%88%E3%81%86%E3%81%8B&qid=1601974975&sr=8-1&tag=googhydr-22)です。

---

# DynamoDBとは

- AWSが提供するNoSQLのデータベース
- フルマネージドで分散データベースの運用とスケーリングに伴う管理作業をまかせることができる
- 高い可用性と耐久性が特徴

---

# RDSとの違い

- 単純なデータの読み書きに強い
- 複雑なデータの更新に弱い
- Lambdaとの相性が良い

---


# 苦しんだこと

1. 大規模データの書き込み
2. バックアップデータのリストア

---

# 大規模データの書き込み

---

## はじめに

こういうよくあるサーバーレスな構成を作りました。

![サーバーレス.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/986ba2df-1973-d7cb-bfb5-ebac6b637a61.png)

ここまではテンプレ（？）

---

## ある日のこと

これに数千件のデータが書き込きこまれることになりました。

![サーバーレス＋大量データ.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/366c164d-ea50-fb4f-9343-2aa3ba7a71e8.png)

これには**数個のテーブルへの書き込みや更新**が生じます。

---

## 結果

残念！DynamoDBへのデータ書き込み途中でタイムアウトが起こりました。Lambdaは予め設定した実行時間を超えるとタイムアウトを起こして502エラーを返します。

![サーバーレス＋大量データ (1).png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/269e9912-2819-c177-b158-017d38e83480.png)

---

## とりあえず対策してみる（１）

タイムアウトが起こったということでLambdaの実行時間やメモリを増設してみました。処理時間は１分くらいでした。

しかしここで知ったのですが、**API Gatewayはタイムアウト時間が[最大30秒](https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/limits.html)に決まっていて、これ以上の拡張ができません**。

---

## とりあえず対策してみる（2）

DynamoDBへの書き込み方法について見直してみました。DynamoDBへのデータの書き込みに[PutItem](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html)を使用していましたが、[BatchWriteItem](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html)を使うようにしました。

ここまでは良かったのですが、問題は**[UpdateItem](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateItem.html)のためのBatchWrite的なAPIがなかったということです**。結局30秒以内に処理を終えることができませんでした。

---

## 最終的に行った対策

最終的にこんな感じの構成になりました。

![最終的な構成.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/35d82bce-5aa1-38fc-83bb-e8bc1b0f9cf0.png)

間にS3が入ることになりました。

---

## ざっくりとした説明

1. Lambda1がアップロードされたデータをS3に書き込み
2. LambdaトリガーをセットしたS3が、データ書き込み後にLambda2を呼び出す
3. Lambda2がDynamoDBへデータを書き込む

これでAPI Gatewayのタイムアウト時間以内にステータスコードを返すことができました。
しかしこの変更でいくつかの問題も生じたのです。まあ苦肉の策という感じでしたね。。。。

---

# バックアップデータのリストア

---

## DynamoDBの自動バックアップ

DynamoDBには[ポイントインタイムリカバリ(PIP)](https://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/PointInTimeRecovery.html)を有効化することができます。これを有効化すると、**ある特定の日時のDynamoDBのデータの状態を復元することができるのです**。

---

## ポイントインタイムリカバリをやってみる

PIPを行うとバックアップテーブルが別のテーブル名で作成されます。

![PIP.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/ad942f79-bf86-93f1-07fb-f371b1636a80.png)

ここまでは良かったのです。

---

## テーブルの移し替えをどうするか

ここでテーブルデータの移し替えを実際に行うのですが、最初に想定していたのは

1. バックアップテーブルを作成する
2. 元テーブルの名前を変更する
3. バップアップテーブルの名前を元テーブルの名前に変更する

なのですが、**DynamoDBにはテーブル名を変更するという機能がありませんでした。**

---

## 結局どうするのか

この問題の解決はできていないのですが、考えた方法は

- 一度削除元テーブルを削除して、バックアップテーブルから元テーブル名のテーブルを作成する
- 元テーブルを削除してバックアップテーブルからのデータを移植するスクリプトを書く（AWS CLIを使う）

どちらもダウンタイムが避けられないのでやりたくはありませんでした。。。

---

# さいごに

今回の失敗で学んだことは、

- DynamoDBで複数テーブルを作ったり、大量のデータ更新をさせるような設計はよろしくない
- PIPの機能は元テーブルへのリストアを公式でサポートはしていない（これについては単純な私の知見不足であればご指摘いただきたいです）

ですね。とりあえず今後の反省ということで。。。
