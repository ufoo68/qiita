---
title: '「AutoGAN: Neural Architecture Search for Generative Adversarial Networks」を読んだ'
tags:
  - 機械学習
  - 論文紹介
private: false
updated_at: '2019-10-02T13:07:17+09:00'
id: e452a3edfc0e36331d28
organization_url_name: null
slide: false
ignorePublish: false
---
# はじめに
社内での輪読会のために[こちらの論文](https://arxiv.org/abs/1908.03835)の内容をまとめます。GANについては研究で扱ったわけではないです。なので翻訳に誤った箇所もあるかと思いますので（あと英語も得意ではないので）、そのときは適宜修正リクエストください。

# Abstract（完全翻訳ではない）
[Neural Architecture Search](https://qiita.com/cvusk/items/536862d57107b9c190e2)の研究が画像分類・セグメンテーションおいて優勢となっている。本論文では、[generative adversarial networks(GAN)](https://qiita.com/taku-buntu/items/0093a68bfae0b0ff879d)のためのNASアルゴリズム**AutoGAN**について紹介する。NASとGANを結合させることは今までにない試みである。
我々は、generator architectural variationsのための探索空間を定義し、探索のガイドのためにController RNNを用いた。そしてパラメーター共有とdynamic-resettingによりプロセスを加速化させた。[Inception score](https://qiita.com/kzykmyzw/items/5c4a6c2ee19ddd59e810#inception-score-1)を報酬として採用し、Multi-level search strategyをNASのパフォーマンスを上げる方法として導入した。
評価実験では、AutoGANの無条件での画像生成の有効性を検証した。特に、[FID](https://qiita.com/kzykmyzw/items/5c4a6c2ee19ddd59e810#fr%C3%A9chet-inception-distance-fid-2)のスコアが**CIFAR-10において12.42**、**STL-10において31.01**という高い従来のGANより高いパフォーマンスを達することができる構造を発見することができた。ソースコードについては[github](https://github.com/TAMU-VITA/AutoGAN)で公開されている。

# Neural Architecture Search(NAS)
NASはニューラルネットワークを自動的に最適化するアルゴリズムである。NASは３つの要素が存在する。

1. 探索空間
  1. 全体的な構造の探索（マクロサーチ）
  2. 各セルごとの探索して事前に定義された方法でスタックする（ミクロサーチ）
2. 最適化アルゴリズム
  1. **強化学習**（ポピュラーな方法）
  2. 遺伝的アルゴリズム
  3. ベイジアン最適化
  4. ランダムサーチ
  5. 勾配ベースの最適化
3. プロキシタスク（学習中に発見したアーキテクチャを効果的に評価するための設計）
  1. 低解像度画像を用いる
  2. 代理モデルでパフォーマンスを予測する
  3. 小さいバックボーンを使う
  4. パラメーター共有を活用する

ほとんどのNASでは、ネットワーク構造もしくはセルが1つのコントローラーで生成される。最近の研究では、「beam search」を使用して、画像分類タスクでNASに「multi-level search」を導入した。アーキテクチャの検索は小さなセルで開始され、最高のパフォーマンスの候補が保持される。 より大きなセルについては、それらに基づいて次の検索ラウンドが継続される。

# 提案手法
GANには２つのネットワークが存在する。

1. Generator（以下**G**）
2. Discriminator（以下**D**）

この２つを学習させる方法として、一方のG(or D)を固定してD(or G)のみを探索する方法を考えたとき、DまたはGの間のパワーに不均衡が容易に生じてしまう。一方で両者を結合して探索すると元々の不安さをさらに悪化させてしまう。そこで、この研究ではNASを使用して**Gのアーキテクチャのみを検索**し、Gが深くなるにつれてDを成長させ、所定のルーチンに従って事前定義されたブロックをスタックすることを提案する。
AutoGANは、探索空間からブロックを選ぶためにRNN controllerを用いた方法に従う。下の図にそのスキームが説明されている。
![スクリーンショット 2019-09-30 13.02.57.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/69ef4d2f-50b1-35e1-74b1-909c5ce3e900.png)
次に、AutoGANの３つの要素について説明する。

## 探索空間
AutoGANはmulti-level architecture search strategyに基づいている。ここでは**(s+5)のタプル要素**を用いる。s番目のセルを(skip_1, ..., skip_s, C, N, U, SC)とする。この時sは０から始まるセルのインデックスである（ただし0番目のセルにはskip_0は存在しない）。

- **skip_i:**現在のs番目のセルが(i-1)番目のセル（iは1~sの範囲）からのskip connectionを入力して取るかどうかを示すバイナリ値。各セルは他の先行セルから複数のスキップ接続を取得できる
- **C:**`pre-activation`と`post-activation`の畳み込みブロックを含む畳み込みブロックタイプ
- **N:**`batch normalization`と `instance normalization`と`no normalization`を含む
- **U:**`bilinear upsampling`と`nearest neighbor upsampling`と`stride 2 deconvolution`などのアップサンプリングを含む（GANで標準なもの）
- **SC:**セル内のショートカットのバイナリ値を示す

下の図でAutoGANの探索空間について説明している。
![スクリーンショット 2019-10-01 12.41.49.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/650fe5d6-fcb5-697f-6917-ac2cdbb7d61d.png)

## プロキシタスク
Inception score(IS)とFID scoreがGANの主な評価の指標となる。FIDスコアの計算にははるかに時間がかかるため、強化学習を介してコントローラーを更新する報酬として、派生した**child modelのIS**を選択する。
パラメーター共有を用いることでNASを効果的にブーストさせることができる。さらにパラメーターの動的リセットの戦略を導入する。GANのトレーニングを長時間行うとモードが崩壊することが確認されていて、共有された崩壊モデルのトレーニングを継続するのは時間の無駄であるためである。モード崩壊が発生すると、通常、トレーニング損失（ヒンジ損失）の分散が非常に小さくなることが観察される。
観察に基づいて、ジェネレーターとディスクリミネーターの両方について、最新のトレーニング損失値を保存する移動ウィンドウを設定する。これらの保存されたトレーニング損失の標準偏差が事前に定義されたしきい値より小さくなると、現在の反復の共有GANのトレーニングが終了する。
共有GANモデルのパラメーターは、現在のイテレーションでコントローラーを更新した後に再初期化される（RNNコントローラーのパラメーターを再初期化はしない）。したがって、歴史的な知識を継承してアーキテクチャー検索をガイドし続けることができる。 動的リセットにより、検索プロセスがより効率的になる。

## 最適化メソッド
２つのパラメーターをセットする。

- RNN controller (θ)
- Generator(とそれに応じたDiscriminator) の共有パラメーター（ω）

学習過程は以下のような擬似コードになる。

```
iters = 0 ;
stage = 0 ;
FDR = False ;
while iters < 90 do
  train (generator, discriminator, FDR);
  train (controller);
  if iters % ustage == 0 then
    save the top K architectures;
    generator = grow (generator) ;
    discriminator = grow (discriminator) ;
    controller = new (controller);
    stage+ = 1;
  end
  if FDR == True then
    // dynamic reset
    initialize (generator);
    initialize (discriminator);
    FDR = False;
  end
  iters+ = 1;
end
```

最初のフェーズでは、θを固定して、いくつかのエポックで共有GANのωをトレーニングする。GANの各トレーニングのイテレーションにて、アーキテクチャの候補がRNN controllerによってサンプルされる。`FDR`はdynamic resetのためのフラグで、トレーニング損失の標準偏差がしきい値より小さくなると`TRUE`となり、直ちにトレーニングが終了される。共有GANは、現在のエポックでのコントローラーのトレーニングが完了するまで再初期化されない。
次に、ωを固定してθをトレーニングする。controllerは、最初に共有ジェネレーターのK個のchild modelをサンプリングする。ISは報酬として計算される。RNN controllerは移動平均ベースの強化学習によって更新される。`ustage`回のトレーニングのあと、トップであるKアーキテクチャが派生アーキテクチャとしてピックアップされる。その間、次の段階のアーキテクチャ検索を進めるために、新しいコントローラが初期化される。

### 共有GANの学習
RNN controllerのポリシー`π(a, θ)`を固定し、共有パラメーターωを標準のGANトレーニングを介して更新する。具体的には、以下のようなヒンジの敵対的損失を使用して交互にトレーニングする。

```math
L_D =E_{x∼q_{data}} [min(0, −1 + D(x)] + E_{z∼p(z)}[min(0, −1 − D(G(z))]
```

```math
L_G = E_{z∼p(z)}[min(0, D(G(z))]
```

さらに、マルチレベルアーキテクチャ検索（MLAS）をAutoGANに導入する。ここでは、ジェネレーター（およびそれに対応する弁別器）が徐々に成長する。MLASは、ビーム検索を使用して、ボトムアップのセル単位で検索を実行する。次のセルを検索するときは、別のコントローラーを使用して、現在の候補セルから上位Kビームを選択し、それらに基づいて次のラウンドの検索を開始する。

### Controllerの学習
ここではωを固定してθを更新する。サンプリングされたchild modelのaのISとして報酬`R(a,ω)`を定義する。RNN controllerはREINFORCEを用いた移動平均ベースのAdamを用いて更新される。また、探索を促進するためにエントロピーを追加する。
この研究ではLSTM controllerを用いている。各タイムステップで、LSTMは隠れ状態ベクトルを出力する。これは、対応するsoftmax分類器によってデコードおよび分類される。そして新しいセルが既存のモデルに追加されて出力画像の解像度が上がると、新しいコントローラーが初期化される。以前の上位Kモデルのアーキテクチャと対応する隠れ状態ベクトルが保存される。隠れ状態ベクトルは、次のセルの操作を検索するための入力として新しいコントローラーに供給される。

### アーキテクチャの導出
最初に、学習したポリシー`π(a, θ)`からいくつかのジェネレーターアーキテクチャをサンプリングする。 次に、報酬R(IS)が各モデルに対して計算される。 次に、最高の報酬の観点から上位Kモデルを選択し、それらをゼロからトレーニングする。 その後、ISを再度評価し、ISが最も高いモデルが最終的な派生ジェネレーターアーキテクチャになる。

# 評価実験
- 学習データ
  - CIFAR-10
  - STL-10（転移性を確かめるため）
- 学習(GAN)
  - 学習率：2e-4
  - loss:ヒンジ
  - optimizer:Adam
  - バッチサイズ
    - generator:128
    - discriminator:64
  - スペクトル正規化をdiscriminatorのみに使用
- 学習(RNN controller)
  - 学習率：3.5e-4
  - optimizer:Adam
  - 1e-4で重み付けされた報酬にコントローラーの出力確率のエントロピーを追加
- 学習(AutoGAN)
  - iterate:90
  - GAN epochs:15/iter
  - RNN controller steps:30/iter
  - Dynamic resettingのための閾値：1e-3
  - 検出されたアーキテクチャのトレーニングを5000回行う

# CIFAR-10の結果
下の図がCIFAR-10で発見されたアーキテクチャ
![スクリーンショット 2019-10-02 12.31.43.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/e9b4d246-9a89-55c6-08ba-fd48bd7d5cd6.png)
従来のGANとの比較をISとFIDで行なったのが下の表
![スクリーンショット 2019-10-02 12.34.38.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/dc934054-5be9-108f-f039-169b11758085.png)
実際に生成された画像が下の写真
![スクリーンショット 2019-10-02 12.36.05.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/056f8de6-c79c-b1b5-fc69-42825386a69b.png)

# STL-10での結果
CIFAR-10で作られたアーキテクチャでSTL-10を学習させた結果を従来のGANと比較した。結果は以下の表。
![スクリーンショット 2019-10-02 12.44.22.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/15fb8037-965d-1bf3-1c0c-ebb1efe0e73a.png)
実際に生成された画像が以下の写真。
![スクリーンショット 2019-10-02 12.46.15.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/35e4434a-c437-bc05-a0c0-51a1052edea7.png)

# Conclusion
さらに従来のGANより高い性能を出すために行うことは以下。

- `attention/self-attention`・`style-based generator`・`relativistic discriminator`・`Wasserstein loss`を用いた探索空間の拡張
- 高解像度の画像を用いたテスト。しかしCIFAR-10の時点で43時間もかかっているのでアルゴリズムの改善が必要
- Discriminatorの探索
- 条件付きGANや半教師付きGANなどのラベルを組み込む機能をつける

# さいごに
この論文を読む前にNASの知識がなかったので、そこから勉強する必要がありました。しかし私が機械学習の研究をやっていた頃（と言っても１年前くらい）にはNASなんて言葉はそんなに聞かなかったような気がするのですが、どうやら今はこのAutoMLが結構熱い分野のようですね。。正直この機械学習の技術の流動の速さに驚きました。また、ここでは論文の`4.3. Ablation Study and Analysis`については省略しています（あまりこの分野に深入りするもりは無かったので）。
あと、これのPythonのコード動かしてみようと思ったのですが、GPU対応のPCでは無かったのでpipで詰まりましたw
