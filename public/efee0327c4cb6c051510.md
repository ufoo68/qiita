---
title: 「Learning to Speak and Act in a Fantasy Text Adventure Game」を読んだまとめ
tags:
  - 機械学習
  - 論文紹介
private: false
updated_at: '2020-10-01T13:29:29+09:00'
id: efee0327c4cb6c051510
organization_url_name: null
slide: false
ignorePublish: false
---
# はじめに

この記事は社内の論文輪講のためにまとめたものです。今回は[Learning to Speak and Act in a Fantasy Text Adventure Game](https://arxiv.org/abs/1903.03094)という論文を読みました。

# 概要

**根拠のある対話**を研究するためのリサーチプラットフォームとして、クラウドソーシングによる大規模なテキストアドベンチャーゲームを紹介します。 
この論文では、以下の設定で最先端の生成モデルと検索モデルをトレーニングした結果について説明します。

* エージェントは他のエージェントと対話しながら、知覚、感情移入、行動することができます。 
* モデルと人間の両方がゲーム内でキャラクターとして行動できます。  

これらのモデルは、過去の対話に加えて、基礎となる世界の状態を効果的に使用して予測を調整できることを示しています。 特に、場所の説明を含むローカル環境の詳細、およびその中に存在するオブジェクト（およびそれらのアフォーダンス）とキャラクター（およびそれらの以前のアクション）に基づいてエージェントの動作と対話をより正確に予測できることを示します。 
上記の設定で成功を収めるために必要な成分を分析し、これらの各要因が、うまく話し、行動できるエージェントとどのように関連しているかを分析します。

# イントロダクション

現在の最先端の研究では**言語が記述する世界**を理解せずに**言語データの統計的規則性のみ**を使用しています。しかしこの論文では、**豊かでまとまりのある（しかし扱いやすい）世界で具体化された対話エージェントは、大規模なコーパスよりも効果的に言語での対話を学習できる**という仮説に基づいて研究を行いました。
そのために私たちは[LIGHT](https://ai.facebook.com/blog/introducing-light-a-multiplayer-text-adventure-game-for-dialogue-research/)と呼ぶ研究プラットフォームを紹介します。
収集したデータセットを使用して、モデルがその環境の知覚と他のスピーカーからの対話に基づいて話し、行動する方法を調査します。この調査では、最新のモデルを私たちのタスクによって評価し、**grounding**（ペルソナや環境設定など）を追加することによる効果について評価します。特に、[**BERTコンテキスト言語モデル**](https://ai-scholar.tech/articles/text-mining/bert-ai-93)を2つの方法で対話のタスクに適合させます。

1. 検索モデルとして高速で実用的な**Bi-Ranker**
2. 推論時間は遅いが、コンテキストと応答の間でより多くの機能の相互相関が可能になる**Cross-Ranker**

 私たちのアブレーション分析は、言語の理解と使用の両方の観点から、基礎の各部分（場所、オブジェクト、キャラクター、他者の行動、自己行動）の重要性を示しています。groundingを使用するモデルは明確な改善を示していますが、人間レベルのパフォーマンスを発揮するレベルではなく、それに関しては将来の課題としています。

#  LIGHT Environment and Task Setup
## LIGHTとは

 LIGHTは、状況に応じた対話を学ぶために設計されたマルチプレイヤーファンタジーテキストアドベンチャーの世界であり、人間、具体化されたエージェントとしてのモデル、および世界自体の間の相互作用を可能にします。それは完全に自然言語で記述された大規模なクラウドソーシングゲームの世界（663の場所、3462のオブジェクト、1755のキャラクター）で構成されています。 そのゲームの世界内で、アクション、エモート、および対話を含むcharacter-drivenな人間と人間のクラウドワーカーの相互作用の大規模なセット（11,000エピソード）を収集し、人間と同様なインタラクションをおこすトレーニングモデルを目指します。フレームワークは[ParlAI](https://parl.ai/projects/light/)で公開されています。以下にその対話の例の一つを示します。

<img width="829" alt="スクリーンショット 2020-04-07 9.05.20.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/ef1e6706-1b57-100d-28d9-a4c9c3afa91d.png">

全体的な要素については以下のTable 1に示されています。

![スクリーンショット 2020-09-30 17.47.58.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/e0311f01-b701-928b-04be-c299fdd536a1.png)

## Locations

私たちは最初に37のベースとなるカテゴリ（田舎、森、城の内外、海岸、墓地、バザール、....）から663の環境をクラウドソーシングしました。以下のTable 2aのように、作業者にはカテゴリーが与えられ、説明、バックストーリー、接続されている場所の名前、含まれているオブジェクトなどを作成するように求められます。

![スクリーンショット 2020-09-30 18.02.44.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/dcfb47a6-acc7-6c88-73df-aa63ab1e0bbe.png)


残りのすべてのタスクは、6つの場所カテゴリー

- 水中アクアポリス
- 凍ったツンドラ
- 超自然的
- 魔法の領域
- 雲の中の都市
- ネザーワールド

を選択し、テストのための場所、キャラクター、オブジェクトの隔離されたセットを提供するために、他のものとは異なるように設計しました。これらは、私たちが「Unseen Test」と呼ぶものを構築するために使用されます。

## Characters

私たちは、動物からトロール、オーク、人間まで、1755人のゲームキャラクターをクラウドソーシングしました。以下のTable 2bにその例が示されています。

![スクリーンショット 2020-09-30 18.08.15.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/e1e8c375-ac02-a08b-c864-c40056535449.png)

## Objects

私たちは3462個のオブジェクトをクラウドソーシングしました。テキストの説明とアフォーダンスのセットで(容器であるか、手に取ることができるか、表面を持つか、武器であるか、身につけることができるか、食べ物であるか、飲み物であるか）、例については以下のTable 2cに示されています。

![スクリーンショット 2020-09-30 18.27.34.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/1c6164a8-bec0-31aa-4429-b5566f140a56.png)


## Actions and Emotes

物理的なアクションには、get, drop, put, give, steal, wear, remove, eat, drink, hug, hitがあり、それぞれ1つまたは2つの引数を取ります。
すべてのアクションは、基礎となるゲーム状態に明確な影響を与え、制約が満たされた場合にのみ実行されます（例えば、後者の例では、エージェントがローブを持っている場合など）。
表情には、拍手、赤面、クリンジ、泣き、ダンス、しかめ面などがあります。エモートには、拍手、赤面、クリングル、泣き声、ダンス、しかめっ面、拗ね声、波動、ウィンク（全部で22個）があり、近くにいるキャラクターにエモートを通知する以外には、ゲーム状態に影響を与えず、キャラクターの行動に影響を与えることができます。詳細な説明はAppendix E を参照のこと。

## Interaction

設定した環境の中で行動したり発言したりするエージェントを評価するために、環境内でのエピソード的な対話の人間と人間のデータセットを収集します。
各対話については、ランダムな場所に2人のキャラクターを配置します（すでに割り当てられている2人のキャラクター、またはランダムに割り当てられたキャラクターのいずれか）。各キャラクターは自分のペルソナ、場所の説明、存在するオブジェクトにアクセスすることができ、相互作用のエピソードが始まります。また2人のキャラクターは、エピソード内で交代で1つのアクション（身体的アクションまたはエモーション）を実行し、1回の交代で1つの台詞を発することができます。
私たちは10,777個のセリフをクラウドソーシングしました。

## Seen and Unseen Test Sets

私たちは2つの異なるテストセットを提供します。Seen test setは、トレーニングセットと同じ世界（場所の集合）で収集された対話から構成され、訓練データに登場する可能性のあるキャラクター、オブジェクト、ペルソナから構成されます。これに対して、Unseen test setは、見られない場所の集合に収集された台詞で構成されています。
Unseen test setは、似たような領域の未知の環境への一般化能力を評価することができ、現在の技術にとってより困難なテストを提供しています。

# 学習方法

アクション、エモート、対話を予測できるさまざまなモデルを検討し、設定内の場所、オブジェクト、およびその他のキャラクターに基づいてgroundingの重要性を探ります。 すべてのモデルで、各入力タイプ（ペルソナ、設定、セルフエモート、パートナーエモートなど）の前に特別なトークンがある大きなテキストシーケンスとしてコンテキストを表します。 私たちは2つのモデルクラスで作業します。

1. 候補となる一連の候補から最大のスコアリング応答を出力するランク付けモデル
2. 単語ごとにデコードする生成モデル

モデルの実装には**PyTorch**を使用します。以下より用いたモデルについて示します。

## Baseline Ranking Methods

ランダムベースライン（候補の中からランダムな候補を選択する）と、TF / IDF重み付けによる単語の重複を使用する情報検索（IR）ベースラインについて示します。ランキング損失を使用して真のラベルの内積を最大化するために、コンテキストと候補のバッグオブワードの[Embedding](https://ishitonton.hatenablog.com/entry/2018/11/25/200332)を[**Starspace**](https://qiita.com/nishiba/items/c0fcf6ad9bf8f6d94438)を用いて学習して、[**fastText**](https://qiita.com/icoxfog417/items/42a95b279c0b7ad26589)より22クラスの中から次のエモートを予測します。最終的に、最良のモデルのパフォーマンスを各予測タスクの人間のパフォーマンスと比較します。

## Transformer Memory Network

[**Transformer**](https://qiita.com/halhorn/items/c91497522be27bde17ce)を用いて、grounding情報（設定、ペルソナ、オブジェクト）から各文の個別の表現（メモリスロット）を生成します（Dinanらの**memory-based ranking model**を使用）。次に、メモリを介して対話コンテキストが与えられた場合に**attention**を実行して、コンテキストのEmbeddingを生成します。 トレーニング時には、バッチ内の他のサンプルが負の候補として使用されます。 感情の予測については、22クラスしかないため、可能な感情の完全なセットに対してランク付けしてトレーニングします。

## BERT Bi-Ranker and Cross-Ranker

**BERT事前トレーニング済み言語モデル**を対話と行動予測のタスクに適合させます。 BERTを活用するための2つのアーキテクチャについて説明します。 まず、 BERTベースの**Bi-Ranker**を使用して、コンテキストのベクトル表現と各候補発話の個別の表現を生成します。 この表現は、BERTの12層の最初の出力を追加の線形層に通すことで得られ、結果として、次元768のEmbeddingが行われます。次に、これらのEmbedding間の内積を介して候補にスコアを付け、ランキング損失を使用してトレーニングします。

第2に、 BERTベースの**Cross-Ranker**は代わりに各候補発話にコンテキストを連結します。  次に、すべての候補についてソフトマックスを計算することにより各候補にスコアが付けられます。 BERTベースのBi-Rankerとは異なり、個々の候補とコンテキストを連結することで、各候補のエンコード時にモデルがコンテキストに注意を払い、各候補のコンテキスト依存表現を構築できます。対照的に、Bi-Rankerは、self-attentionを使用して候補とコンテキスト表現を構築できますが、コンテキストに基づいてそれらの表現を変更することはできません。 ただし、**Cross-Encoderは、連結表現ごとに再計算する必要があるため計算コストがはるかに高いです**（対話検索の場合、Bi-Rankerよりも約11,000遅くなります）。それに対してBi-Rankerは候補をキャッシュして再利用できます。

## Generative Models

コンテキスト機能（会話、ペルソナ、設定など）をエンコードするために、Transformer Memory Networkを同様に用います。ただし、アクション、エモート、または対話のシーケンスを予測するために、Transformerを使用して、エンコーダーの出力に注意しながらデコードします。
アクション生成のタスクでは、真のアクションシーケンスをランク付けするためのランク付けモデルの候補のセットは、有効なアクションのセットによって制約されます。 たとえば本がない場合、キャラクターは本を拾うことができません。生成モデルでは可能な候補のセットの対数尤度を計算し、正規化して出力スペースを有効なアクションに制限して結果を改善します。

## Model Inputs

実験で考慮しているすべての基礎となる特徴（設定、オブジェクト、キャラクター＋ペルソナ、アクション、エモート、対話）を含む場合の、モデルに与えられた正確な入力表現をFigure 2に示します。

![スクリーンショット 2020-10-01 9.51.50.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/b793182d-7ef9-15d6-1737-70ceb3bbd995.png)



# 評価

モデルを評価するために、アクションと感情予測のパーセンテージ精度を計算します。対話については、正解となる発話とランダムに選択された他の19のランク付けモデル候補から選択させる**分類問題**としてその正解率を評価します（Recall@1/20）。**Generative model**の評価については[Perplexity](https://www.slideshare.net/hoxo_m/perplexity)と[F1スコア](https://note.com/suhahide/n/nd6768830c4ac)を計算します。
この評価は人間に対しても同様に行います（詳細はAppendix Fにて）。

# 結果

## Comparison of Models and Baselines

ランク付モデルの比較が以下の表になります。

![スクリーンショット 2020-09-25 10.42.21.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/5affae7e-5f5a-af9a-71c7-51aee1fcd423.png)

この結果では、BERT-basedのモデルが高い性能を示していました。しかしHuman performanceに比べて、Test Seenでは11point、Test Unseenでは21pointの差があるのでまだ改善の余地があります。

## Data Inter-connectedness and Coverage

以下のTable 3は、Starspace embeddingモデル（事前学習なし）でのEmbeddingについて示しています。学習可能な概念の多様性と、文字、場所、オブジェクト、アクション、およびそれらを記述する言語の間の豊かな構造が明らかに存在しています。

![スクリーンショット 2020-09-28 14.37.02.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/28b96b03-69b3-3f9c-aff7-4b0b1b2bb7e3.png)

また、これらの関係を示す追加のt-SNE プロットとヒートマップをAppendix Gに示しています。

## Effect of Various Environment Features

私たちは、対話だけでなく、設定の説明、キャラクターのペルソナ、説明文付きのプレゼントオブジェクトなど、環境に関する大量の情報を各モデルに提供しています。その有用性についてTable 5,6に示しています。

![スクリーンショット 2020-10-01 9.27.52.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/c25ad754-eb1e-cb5c-a7eb-76fba32a04a3.png)

![スクリーンショット 2020-10-01 9.27.58.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/d8cf40cb-aa7a-aa93-0486-8a57bf893ff8.png)


対話タスクでは、すべての環境情報にアクセスできることが、検索モデルと生成モデルの両方で最高のパフォーマンスを提供します。対話の訓練だけではパフォーマンスは大幅に低下しますが、過去の行動やペルソナ、設定の説明などの下地となる情報を追加する実験を行うたびにスコアは向上します。
オブジェクトの機能を追加することに対してはあまり精度の改善はされませんでした（存在し得るオブジェクトの量が多く、オブジェクトの記述が長い傾向があるため、モデルがそのような情報を対話、行動、またはエモーション予測タスクに関連付けることは困難である可能性があります）。 ペルソナを追加することで大きな改善がされましたが、これはキャラクターの言うこと（すること）を形作っているのですから、理にかなっています。
過去の行動履歴のみを使用した場合と比較して、対話履歴を使用した場合のアクションシーケンスとエモート予測は大幅に改善されています。その他の特徴は、一般的にこのケースでは影響が少ないですが、それでもいくつかの改善が見られます。
最も重要なことは、すべてのタスクにおいて対話データのトレーニングが良いパフォーマンスを発揮するために必要であるということです。行動と感情だけをコンテキストとして利用すると、行動と感情の予測タスクでも最悪の結果になります。


## Context affects predicted utterances

BERTベースのBi-Rankerを使用して、コンテキストを変更し、予測された対話、アクション、およびエモートの変化を調べることにより、予測に対する環境コンテキストの影響を調査します。

以下のTable 9の例では入力された対話と話者によって予測したアクションに強い影響を与えています。
例えばパートナーがアイテムを要求したときに、データセットが明示的に示していないにもかかわらずパートナーに依存するアイテム取得のアクションを予測します。

![スクリーンショット 2020-09-25 10.45.31.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/ebb91a8a-7e37-d647-3cff-334e9c54e896.png)

同じような例が以下のTable 8にも見られました。対話と感情の入力を変更すると、様々な感情を予測しました。さらに会話のコンテキストを固定したままパートナー名を変更することで予測される感情も異なり、例えばmermaidが"I will battle him"といったときには"stare"と予測したことに対してorcが発言したときには"nob"という感情を予測しました。

![スクリーンショット 2020-09-25 10.45.26.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/a36d6cb1-53b4-b11f-7a2a-fc6f6e8376e0.png)

最後に以下のTable 7のように、予測された対話がセリフとパートナーが同じであっても、環境によってことなる結果となることがわかりました。
例えば、同じfoodというテキストでも環境に応じた対話を予測していました。 fishmonger’s stallでは、人間のエージェントが魚を買う顧客であるかどうかを尋ねましたが、desert dunesでは、間違った場所を探している可能性があることを示唆していました。

![スクリーンショット 2020-09-25 10.45.20.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/209689/9b01341b-85a2-e17c-3039-e1312ab51131.png)

# 結論

この論文ではクラウドソースのファンタジーテキストアドベンチャーゲーム研究プラットフォームを紹介しました。その世界でのエージェント（モデルと人間の両方）は行動でき、場所、オブジェクト、その他のキャラクターの豊かで多様な環境で話します。
また、さまざまなモデルと、環境に存在する接地情報を活用するそれらの能力を分析しました。
この作業により、基礎となる言語学習の将来の研究が可能になり、エージェントが他のエージェントを含む全体的な世界をモデル化できるようになることを願っています。
