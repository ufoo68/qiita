---
title: 「スマートスピーカーを遊びたおす会 vol.9」に参加してきた
tags:
  - 勉強会メモ
  - スマートスピーカー
private: false
updated_at: '2020-02-19T21:18:02+09:00'
id: f86c1580eaae7de676a8
organization_url_name: null
slide: false
ignorePublish: false
---
# はじめに
[スマートスピーカーを遊びたおす会 vol.9](https://kotodama.connpass.com/event/163156/)の内容についてまとめます。今回はコロナウイルスの流行を考慮して、オンラインでの開催となりました。

# 湊川さん「マンガでわかるLINE Clova開発入門！」
[わかばちゃんと学ぶシリーズ](https://webdesign-manga.com/books/)の方の登壇でした。実際のマンガは[ここのTECH PLAYのサイト](https://techplay.jp/column/354)で公開されてます。基本はこのマンガの内容に即したセッションだったので、リンク先のマンガを読んでもらう方がいいと思います。かなりわかりやすいです。
こういった開発にはサーバーを用意する必要があるのですが、サーバーレス（FaaS）を用いればアプリケーションを書くことだけで開発できてしまうのが素晴らしいですね。ここでは[Azure Functions](https://azure.microsoft.com/ja-jp/services/functions/)が紹介されました。

一応わたしも[入門記事](https://qiita.com/ufoo68/items/67e90f46aae2782932f9)を書いてます（しょうもない宣伝ですが）。まあ、これ見るよりマンガを見てもらう方が１００億倍いいです。

# もっちーさん「好きなもの×VUI」
[デニーズ](https://www.dennys.jp/)とスマホアプリとVUIを組み合わせたものを作った、という内容でした。
作ったものとしては、デニーズで食べたものをスマホアプリを介して記録してスマートスピーカーからオススメのメニューを紹介するという内容のスキルのようです。
スマホアプリ側では[AirTable](https://airtable.com/)というクラウドのデータベースを使用し、スマートスピーカー側ではスキルの開発に[Voiceflow](https://www.voiceflow.com/)を使用していました。内容の一部は[ここの記事](https://qiita.com/Motchy_1204/items/21c24a05280b05e0fac8)で公開されているようです。

Voiceflowを用いればコードを書くことなくスキルの開発ができるのがいいです！難点としてはこのVoiceflowはUIの更新の頻度が高く、ググって出てくる記事とUIが違ったりして、参考文献を探すのが難しいという点だそうです。

# 小城さん「スマスピを怠惰に使うスマスピ」
このセッションでは、スマートスピーカーの課題として、質問の意図を解釈してくれない、スマート家電をうまくコントロールできないといったことを解消するスキルを開発したという内容でした。
その課題の解決方法として、**スマートスピーカーに適切な指示を出すスマートスピーカー**を開発したそうです。

指示機（スマートスピーカーに指令送るVUI）はスマホアプリとして、開発環境にはAndroidを用いて行ったようです。VUIアプリの開発にはアプリを呼び出すためのウェイクとインテントの理解が必要になりますが、今回は[pocketsphinx](https://github.com/cmusphinx/pocketsphinx)というライブラリを用いて音声認識を行い、[Daialogflow](https://dialogflow.com/)を用いて自然言語処理を行って、合成音声にはAndroidの標準のAPIを用いて行ったそうです。

Androidでもライブラリを駆使すれば機械学習の技術がなくてもVUIの開発ができそうですね！

# さいごに
最近VUIの開発（特にClova）に飽きがちだったのですが、今回の話（特に最後のセッション）を聞いてまだまだスマートスピーカーの開発には可能性があるなと感じました。
